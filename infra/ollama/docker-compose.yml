name: ollama
services:
  ollama:
    profiles:
      - ollama
    image: ollama/ollama:0.13.5
    container_name: ollama
    # ports:
    #   - "${OLLAMA_HOST_PORT}:${OLLAMA_PORT}"
    expose:
      - ${OLLAMA_PORT}
    volumes:
      - ollama-data:/root/.ollama
    environment:
      # [필수 추가] Ollama가 모든 네트워크 인터페이스(Docker 내부)에서 수신하도록 설정
      # 기본 포트가 11434라면 ${OLLAMA_PORT}는 11434와 일치해야 합니다.
      - OLLAMA_HOST=0.0.0.0:${OLLAMA_PORT}
      # [GPU 필수] 컨테이너가 할당된 GPU를 사용하도록 명시
      - NVIDIA_VISIBLE_DEVICES=all
    networks:
      infra_net:
        ipv4_address: 172.19.0.40
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s  # 모델 로드 시간을 고려하여 여유 있게 설정
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          memory: 4G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    labels:
      - "traefik.enable=true"
      # Ollama API 라우터 (https://ollama.${DEFAULT_URL})
      - "traefik.http.routers.ollama.rule=Host(`ollama.${DEFAULT_URL}`)"
      - "traefik.http.routers.ollama.entrypoints=websecure"
      - "traefik.http.routers.ollama.tls=true"

      # [중요] 내부 포트 11434 연결
      - "traefik.http.services.ollama.loadbalancer.server.port=${OLLAMA_PORT}"
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # 2. Open WebUI 서비스 (선택 사항: ChatGPT 같은 웹 인터페이스)
  open-webui:
    profiles:
      - ollama
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    # ports:
    #   - "${OLLAMA_WEBUI_HOST_PORT}:${OLLAMA_WEBUI_PORT}" # 브라우저에서 localhost:3000 으로 접속
    environment:
      - OLLAMA_BASE_URL=http://ollama:${OLLAMA_PORT}  # 도커 네트워크 내부 통신
      # --- RAG 설정 추가 ---
      # 벡터 DB 연결 설정
      - VECTOR_DB_URL=http://qdrant:${QDRANT_PORT}
      # 임베딩(텍스트를 숫자로 변환) 작업을 Ollama에게 맡김
      - RAG_EMBEDDING_ENGINE=ollama
      - RAG_EMBEDDING_MODEL=qwen3-embedding:0.6b
    volumes:
      - ollama-webui:/app/backend/data
    depends_on:
      ollama:
        condition: service_healthy
    restart: unless-stopped
    networks:
      infra_net:
        ipv4_address: 172.19.0.42
    labels:
      - "traefik.enable=true"

      # 챗봇 UI 라우터 (https://chat.${DEFAULT_URL})
      - "traefik.http.routers.open-webui.rule=Host(`chat.${DEFAULT_URL}`)"
      - "traefik.http.routers.open-webui.entrypoints=websecure"
      - "traefik.http.routers.open-webui.tls=true"

      # [중요] 내부 포트 8080 연결 (Open WebUI 기본 포트)
      - "traefik.http.services.open-webui.loadbalancer.server.port=8080"
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  ollama-exporter:
    profiles:
      - ollama
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 128M
    image: lucabecker42/ollama-exporter:latest
    container_name: ollama-exporter
    environment:
      - OLLAMA_HOST=ollama:${OLLAMA_PORT}
    ports:
      - "${OLLAMA_EXPORTER_HOST_PORT}:${OLLAMA_EXPORTER_PORT}"   # /metrics
    restart: unless-stopped
    networks:
      infra_net:
        ipv4_address: 172.19.0.43
    depends_on:
      ollama:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
